{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wscvRoo_Y2bp"
   },
   "source": [
    "<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\"  width=400></p>\n",
    "\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lg09ve27Y2br"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gbpu-GrgY2bv"
   },
   "source": [
    "### 1. Нахождение сложной производной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZKVcvtTY2bw"
   },
   "source": [
    "Найдите производную по x от функции \n",
    "$$\\sin\\left(\\tan(x)\\frac{x^2}{y} + \\ln(e^{-x^2 + 3}+x^3y)\\right)\\tan(x^2e^{x^9})$$\n",
    "\n",
    "При этом надо пользоваться встроенным в PyTorch autograd. Численное вычисление производной может не дать нужный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihvUiIDQY2bx"
   },
   "outputs": [],
   "source": [
    "def find_x_derivative(x, y):\n",
    "    x = torch.autograd.Variable(torch.Tensor([x]),requires_grad = True)\n",
    "    out = torch.sin( torch.tan(x)*(x * x / y) + torch.log(torch.exp(-x * x + 3) + x * x * x * y) ) * torch.tan( x * x * (torch.exp(x**9)))\n",
    "    out.backward()\n",
    "    #print(x)\n",
    "    return x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.0207])\n"
     ]
    }
   ],
   "source": [
    "print(find_x_derivative(1, 21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "mNbn5UzGY2b0"
   },
   "source": [
    "# 2. Нахождение косинусной близости\n",
    "\n",
    "Вам даны две матрицы A и B. Необходимо посчитать косинусную близость между строчками матрицы A и столбцами матрицы B. Ответ - матрица чисел, где номер строки - номер строки из матрицы А, а номер столбца - номер столбца из В, от которых бралась косинусная близость.\n",
    "\n",
    "Напомним, что косинусная близость двух векторов - косинус угла между ними. В n-мерном пространстве косинус угла между веткорами удобнее всего через скалярное произведение:\n",
    "$$\\cos(angle(x, y)) = \\frac{x \\cdot y}{\\left\\|x\\right\\| \\left\\|y\\right\\|}$$\n",
    "\n",
    "(Наша операция очень похожа на умножение матриц)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9r2uiysQY2b1"
   },
   "outputs": [],
   "source": [
    "def get_cos_sim(A, B):\n",
    "    \"\"\"\n",
    "        A, B - torch float tensors\n",
    "    \"\"\"\n",
    "    res = torch.mm(a / torch.norm(a, dim = 1, keepdim = True), b / torch.norm(b, dim = 0, keepdim = True))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1., -47.,  25.,  -3.],\n",
      "        [ 10.,  17., -15.,  22.],\n",
      "        [ -3.,  -7.,  26.,  36.],\n",
      "        [ 12., -27., -42.,   0.]])\n",
      "tensor([[-5.0000e+01, -1.3000e+01,  1.0000e+00,  1.0000e+01,  1.2420e+03],\n",
      "        [ 2.1000e+01,  4.8000e+01, -1.3000e+01, -1.4000e+01, -2.0000e+01],\n",
      "        [ 2.0000e+01,  1.5000e+01,  1.1000e+01,  4.3000e+01,  1.1000e+01],\n",
      "        [ 1.1000e+01,  1.0300e+02,  1.4700e+02,  2.7000e+01, -8.0000e+00]])\n",
      "tensor(0.1498)\n"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1, -47, 25, -3], [10, 17, -15, 22], [-3, -7, 26, 36], [12, -27, -42, 0]])\n",
    "print(a)\n",
    "b = torch.FloatTensor([[-50, -13, 1, 10, 1242], [21, 48, -13, -14, -20], [20, 15, 11, 43, 11], [11, 103, 147, 27, -8]])\n",
    "print(b)\n",
    "print(torch.mean(get_cos_sim(a, b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BR_2JtdtY2b4"
   },
   "source": [
    "# 3. Линейная регрессия\n",
    "\n",
    "Раньше мы самостоятельно считали производные, чтобы находить веса линейной регрессии с помощью градиентного спуска. Теперь нам нужно использовать для этого PyTorch и его autograd. \n",
    "\n",
    "**Важно**: на самом деле .backward не обновляет содержимое матриц с производными (some_tensor.grad), а прибавляет к ним только что посчитаные значения проивзодных. Это значит, что вызвав .backward дважды, вы получите удвоенную производную. Так как мы обновляем веса в цикле и много раз вызываем .backward, то очень быстро мы получим мусор в some_tensor.grad, если не будем его каждый раз обнулять. Таким образом, в конц итериации после использования производных обнулите значения в матрице производных для всех нужных Вам переменных. Делается это вот так \n",
    "> some\\_tensor.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbuGEdgBY2b5"
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def get_loss(self, preds, y):\n",
    "        \"\"\"\n",
    "            @param preds: предсказания модели\n",
    "            @param y: истиные значения\n",
    "            @return mse: значение MSE на переданных данных\n",
    "        \"\"\"\n",
    "        # возьмите средний квадрат ошибки по всем выходным переменным\n",
    "        # то есть сумму квадратов ошибки надо поделить на количество_элементов * количество_таргетов\n",
    "        loss = preds - y\n",
    "        return torch.sum(loss * loss) / loss.numel()\n",
    "    \n",
    "    def init_weights(self, input_size, output_size):\n",
    "        \"\"\"\n",
    "            Инициализирует параметры модели\n",
    "            W - матрица размерности (input_size, output_size)\n",
    "            инициализируется рандомными числами из\n",
    "            uniform распределения (torch.rand())\n",
    "            b - вектор размерности (1, output_size)\n",
    "            инициализируется нулями\n",
    "        \"\"\"\n",
    "        torch.manual_seed(0) #необходимо для воспроизводимости результатов\n",
    "        self.W = torch.rand(input_size, output_size,  requires_grad = True)\n",
    "        self.b = torch.zeros(1, output_size, requires_grad = True)\n",
    "\n",
    "    def fit(self, X, y, num_epochs = 1000, lr = 0.001):\n",
    "        \"\"\"\n",
    "            Обучение модели линейной регрессии методом градиентного спуска\n",
    "            @param X: размерности (num_samples, input_shape)\n",
    "            @param y: размерности (num_samples, output_shape)\n",
    "            @param num_epochs: количество итераций градиентного спуска\n",
    "            @param lr: шаг градиентного спуска\n",
    "            @return metrics: вектор значений MSE на каждом шаге градиентного\n",
    "            спуска.\n",
    "        \"\"\"\n",
    "        self.init_weights(X.shape[1], y.shape[1])\n",
    "        metrics = []\n",
    "        for _ in range(num_epochs):\n",
    "            preds = self.predict(X)\n",
    "            # сделайте вычисления градиентов c помощью Pytorch и обновите веса\n",
    "            # осторожнее, оберните вычитание градиента в \n",
    "#                 with torch.no_grad():\n",
    "#                     #some code\n",
    "            # иначе во время прибавления градиента к переменной создастся очень много нод в дереве операций\n",
    "            # и ваши модели в будущем будут падать от нехватки памяти\n",
    "            self.get_loss(preds, y).backward()\n",
    "            with torch.no_grad():\n",
    "              self.W -= self.W.grad * lr\n",
    "              self.b -= self.b.grad * lr\n",
    "              self.W.grad.zero_()\n",
    "              self.b.grad.zero_()\n",
    "            metrics.append(self.get_loss(preds, y).data)\n",
    "        return metrics\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.W + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQ8GJjFKaY6r"
   },
   "source": [
    "1. Сгенерируйте данные с помощью make_regression с параметрами n_targets=3, n_features=2, noise=10, random_state=42. \n",
    "2. Обучите модель линейной регрессии, оставив в fit параметры num_epochs и lr по умолчанию (обратите внимание, что перед обучением нужно привести данные к типу, использующимся в torch) \n",
    "2. Посчитайте среднее значение метрики MSE по всем итерациям цикла в fit (массив из значений MSE на каждой итерации возвращается из метода fit). Ответом, который необходимо сдать в систему, будет число, округленное до 3х знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOVkSg_0Y2b8"
   },
   "outputs": [],
   "source": [
    "X, Y = datasets.make_regression(n_targets = 3, n_features = 2, noise = 10, random_state = 42)\n",
    "X = torch.from_numpy(X).float()\n",
    "Y = torch.from_numpy(Y).float()\n",
    "model = LinearRegression()\n",
    "mse = model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMgiJA_Va6g_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4256.561\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJVuCWOxbACZ"
   },
   "source": [
    "Здесь предлагаем протестировать метод predict удобным вам образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XF5Rw27ba-mj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  6.8541,   0.5543,  -1.5183],\n",
      "        [-56.6351, -42.0323, -39.0554],\n",
      "        [-62.4823, -31.9040, -25.9731],\n",
      "        [-42.1749, -32.7359, -30.9805],\n",
      "        [  8.4156,  15.5514,  15.8258],\n",
      "        [-53.5753, -26.0870, -20.8924],\n",
      "        [ 45.9922,  33.3924,  29.3737],\n",
      "        [ 31.4741,  14.5750,  10.1026],\n",
      "        [ 66.9552,  45.2404,  39.1624],\n",
      "        [-16.9052, -11.5615, -11.0675],\n",
      "        [-11.2921,  -0.6256,   0.6923],\n",
      "        [ 43.6821,  15.3659,   8.6121],\n",
      "        [ 36.0577,  18.8220,  14.1928],\n",
      "        [  3.1521,  -2.0366,  -3.8338],\n",
      "        [-83.2639, -57.4035, -51.8676],\n",
      "        [ 18.9995,  11.4185,   8.8614],\n",
      "        [-39.4610, -19.9890, -16.5138],\n",
      "        [-21.7515, -24.2949, -25.0953],\n",
      "        [ 44.3900,  25.7567,  20.7032],\n",
      "        [ -3.4867, -10.4673, -12.4412],\n",
      "        [ 30.3031,  30.5916,  29.1889],\n",
      "        [-17.6429,  -7.5654,  -6.2171],\n",
      "        [-12.7887,  -4.2539,  -3.2819],\n",
      "        [ 29.5546,  22.2569,  19.5261],\n",
      "        [ -7.4601,   3.1827,   4.4151],\n",
      "        [-17.5622,  -1.8388,   0.5079],\n",
      "        [-16.7437,  -9.1646,  -8.2781],\n",
      "        [ 17.5066,  11.1163,   8.8017],\n",
      "        [ -9.8327,  -5.6332,  -5.4919],\n",
      "        [ 69.2904,  55.6596,  50.9641],\n",
      "        [-68.2120, -41.7505, -36.4274],\n",
      "        [-42.7499, -27.7112, -24.9516],\n",
      "        [ 37.1757,  21.3433,  16.9390],\n",
      "        [-33.3095, -25.4712, -24.1874],\n",
      "        [  2.0986,  -2.3024,  -3.9377],\n",
      "        [ 64.3719,  45.0702,  39.4745],\n",
      "        [-40.5622, -23.0164, -19.8590],\n",
      "        [ 15.8435,   4.6562,   1.5272],\n",
      "        [-45.2814, -25.7479, -22.1384],\n",
      "        [ 96.8626,  56.3402,  46.2962],\n",
      "        [-17.2257, -17.7900, -18.3358],\n",
      "        [-50.9533, -45.6406, -44.4299],\n",
      "        [ 86.4989,  41.7009,  31.1193],\n",
      "        [-69.2854, -58.7084, -56.1764],\n",
      "        [ 74.9833,  45.3850,  37.7402],\n",
      "        [ 52.7202,  29.0621,  22.9417],\n",
      "        [ 34.9658,  19.9904,  15.7847],\n",
      "        [-78.9975, -59.1353, -54.7524],\n",
      "        [-18.2339,  -2.2921,   0.1076],\n",
      "        [-84.1820, -55.7618, -49.7529],\n",
      "        [-10.3466,  -6.7854,  -6.7463],\n",
      "        [ -7.4636, -15.7737, -17.8987],\n",
      "        [ 74.6812,  46.9942,  39.6944],\n",
      "        [-21.7290, -24.3751, -25.1942],\n",
      "        [-48.0320, -35.5136, -33.0885],\n",
      "        [-16.9023, -16.1623, -16.4840],\n",
      "        [ 50.5764,  25.6225,  19.3181],\n",
      "        [ 40.3891,  35.8114,  33.3327],\n",
      "        [ 52.8828,  26.3220,  19.6840],\n",
      "        [-63.0019, -62.8994, -62.3563],\n",
      "        [-28.3303, -28.7374, -29.0198],\n",
      "        [-40.7046, -31.3551, -29.6467],\n",
      "        [ 10.0846,   9.3318,   8.1733],\n",
      "        [-38.1027, -29.1030, -27.5117],\n",
      "        [-50.9520, -27.6590, -23.2632],\n",
      "        [-40.8724, -37.2938, -36.6042],\n",
      "        [-65.2916, -33.7498, -27.5886],\n",
      "        [ 21.8516,   0.3729,  -4.7067],\n",
      "        [-92.2370, -63.5664, -57.3424],\n",
      "        [  1.1914,  -5.7584,  -7.8260],\n",
      "        [ 41.3171,  30.3969,  26.7750],\n",
      "        [ -1.9421,  -8.0681,  -9.9233],\n",
      "        [-19.6313, -24.5548, -25.8218],\n",
      "        [ -4.7424,  -0.3880,  -0.3272],\n",
      "        [-81.8427, -63.2898, -59.0786],\n",
      "        [-37.6461, -23.9585, -21.5465],\n",
      "        [-62.1122, -43.8538, -40.1132],\n",
      "        [ 88.4835,  46.2414,  36.0705],\n",
      "        [ 17.7271,   9.9135,   7.3422],\n",
      "        [-66.0679, -51.5974, -48.4440],\n",
      "        [  7.5004,   1.8009,  -0.1790],\n",
      "        [ 79.3374,  60.7710,  54.9881],\n",
      "        [ 79.9935,  58.0429,  51.6466],\n",
      "        [-41.1501, -22.5585, -19.2035],\n",
      "        [ 94.4313,  57.5752,  48.2322],\n",
      "        [-53.1621, -46.2025, -44.6533],\n",
      "        [-34.8253, -24.8024, -23.0994],\n",
      "        [ 13.2596,   0.8909,  -2.3926],\n",
      "        [ 65.6393,  37.3542,  30.1402],\n",
      "        [-70.3365, -37.6835, -31.2184],\n",
      "        [-25.3068, -19.9214, -19.2419],\n",
      "        [-18.5902, -13.7276, -13.2831],\n",
      "        [-25.7686, -25.8951, -26.1822],\n",
      "        [  4.1213,   3.6005,   2.6097],\n",
      "        [ 19.9836,   4.3068,   0.2946],\n",
      "        [-85.7524, -55.9377, -49.6485],\n",
      "        [ 11.6251,   9.8971,   8.5332],\n",
      "        [-27.0835, -25.2083, -25.1128],\n",
      "        [ -4.0346,  11.5672,  13.6055],\n",
      "        [ 26.5931,  18.3613,  15.5279]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[homework]pytorch_basics.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
